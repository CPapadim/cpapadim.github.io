<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Cpapadim.GitHub.io by CPapadim</title>
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-dark.css">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"></script>
    <script src="javascripts/main.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>Cpapadim.GitHub.io</h1>
        <p></p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://github.com/CPapadim" class="button fork"><strong>View On GitHub</strong></a>
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        <h3>
<a id="hello-im-harry" class="anchor" href="#hello-im-harry" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Hello, I'm Harry.</h3>

<p>I'm a quantitative storyteller.  I enjoy taking strings of words in the form of questions, turning them into numbers and math, using data to find quantitative answers, and finally turning those quantitative answers into compelling stories.</p>

<p>On this page you will find a few examples of some of the projects I've worked on. </p>

<h3>
<a id="signal-processing-package" class="anchor" href="#signal-processing-package" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Signal Processing Package</h3>

<p>In order to tell truly compelling stories about data a storyteller often needs to create customized storytelling tools.  I wrote this package to help me tell stories about how brains work.  It can analyze time series of action potentials and local field potentials from the brain in both the frequency and time domains to help users uncover how these different brain signals relate to each other and contribute to driving behavior.  </p>

<p><a href="https://github.com/CPapadim/Signal-Processing-Toolkit">Signal Processing Toolkit</a></p>

<p>This tool is now being used by a new generation of upcoming scientists in the Snyder Laboratory. </p>

<h3>
<a id="computational-modeling-and-machine-learning" class="anchor" href="#computational-modeling-and-machine-learning" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Computational Modeling and Machine Learning</h3>

<p>How does your brain compute the trajectory your arm must move in order to reach an object?  It has to take into account where your eyes are looking, where your hand is now, and where the object is.   First, it needs to calculate the distance between your hand is and where your eyes are looking.  We found that to perform this computation the brain uses the response gain of neurons - by making the gain of eye position and hand position equal and opposite.</p>

<p>I built the neural network model below to model these findings,  The network can learn how to compute the reaching to objects in space through training on a set of training data of objects and reaches.  When we examine the neurons in the network we find that, like what we see in the actual brain, the artificial neural network uses the response gain of neurons to compute the distance between the eye position and the hand position.  </p>

<p><a href="https://github.com/CPapadim/Neural-Network-with-Back-Propagation">Artificial Neural Network with Backpropagation</a></p>
      </section>
      <footer>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://twitter.com/michigangraham">mattgraham</a></small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
    
  </body>
</html>
